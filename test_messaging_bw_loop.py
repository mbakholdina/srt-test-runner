""" 
Bandwidth loop test.

A script that runs 1 receiver and N senders (concurrently, in parallel) 
which stream with a specified bitrate. This is done iteratively every time
with a different value of bitrate what helps to determine a maximum 
availabale bandwidth at the moment of running the script.
"""
import concurrent.futures
import configparser
import logging
import pathlib
import signal
import shutil
import subprocess
import sys
import time
import typing

import attr
import click
import fabric
import paramiko

import shared


# TODO:     Add an option to download stats and Wireshark dumps via scp (fabric),
#           Adjust time and the process of running N senders concurrently,
#           Test the script on Windows with regard to ssh-agent,
#           Disbale password promt (fabric),
#           Fix the problem with carriage (\r\n) generated by pseudo-terminal,
#           Add running tshark remotely on a receiver side via SSH,
#           Add running sender side application remotely via SSH (?),
#           Improve documentation,
#           Disable warnings from paramiko


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)-15s [%(levelname)s] %(message)s',
)
logger = logging.getLogger(__name__)


@attr.s
class GlobalConfig:
    """
    Global configuration settings.
    """
    rcv_ssh_host: str = attr.ib()
    rcv_ssh_username: str = attr.ib()
    rcv_path_to_srt: str = attr.ib()
    snd_path_to_srt: str = attr.ib()
    snd_tshark_iface: str = attr.ib()
    dst_host: str = attr.ib()
    dst_port: str = attr.ib()
    algdescr: str = attr.ib()
    scenario: str = attr.ib()

    # TODO: From section instead of filepath
    @classmethod
    def from_config_filepath(cls, config_filepath: pathlib.Path):
        parsed_config = configparser.ConfigParser()
        with config_filepath.open('r', encoding='utf-8') as fp:
            parsed_config.read_file(fp)
        return cls(
            parsed_config['global']['rcv_ssh_host'],
            parsed_config['global']['rcv_ssh_username'],
            parsed_config['global']['rcv_path_to_srt'],
            parsed_config['global']['snd_path_to_srt'],
            parsed_config['global']['snd_tshark_iface'],
            parsed_config['global']['dst_host'],
            parsed_config['global']['dst_port'],
            parsed_config['global']['algdescr'],
            parsed_config['global']['scenario']
        )


@attr.s
class BandwidthLoopTestConfig:
    """
    Bandwidth loop test config.
    """
    bitrate_min: int = attr.ib()
    bitrate_max: int = attr.ib()
    bitrate_step: int = attr.ib()
    time_to_stream: int = attr.ib()

    @classmethod
    def from_config_filepath(cls, config_filepath: pathlib.Path):
        parsed_config = configparser.ConfigParser()
        with config_filepath.open('r', encoding='utf-8') as fp:
            parsed_config.read_file(fp)
        return cls(
            int(parsed_config['bw-loop-test']['bitrate_min']),
            int(parsed_config['bw-loop-test']['bitrate_max']),
            int(parsed_config['bw-loop-test']['bitrate_step']),
            int(parsed_config['bw-loop-test']['time_to_stream'])
        )


@attr.s
class ExperimentParams:
    # TODO: Make default = None
    rcv_attrs_values: typing.Optional[typing.List[typing.Tuple[str, str]]] = attr.ib()
    rcv_options_values: typing.Optional[typing.List[typing.Tuple[str, str]]] = attr.ib()
    snd_attrs_values: typing.Optional[typing.List[typing.Tuple[str, str]]] = attr.ib()
    snd_options_values: typing.Optional[typing.List[typing.Tuple[str, str]]] = attr.ib()
    # Information needed to form .csv stats and .pcapng WireShark
    # files' names
    description: str = attr.ib()
    # in seconds
    time_to_stream: int = attr.ib()


def bw_loop_test_generator(
    global_config,
    test_config
):

    # TODO: Check whether it will work as a property of ExperimentParams

    for bitrate in range(test_config.bitrate_min, test_config.bitrate_max, test_config.bitrate_step):
        # Calculate number of packets for time_to_stream sec of streaming
        # based on the target bitrate and packet size
        repeat = test_config.time_to_stream * bitrate // (1456 * 8)
        maxbw  = int(bitrate // 8 * 1.25)
        
        rcv_attrs_values = [
            ('rcvbuf', '12058624'), 
            ('smoother', 'live'), 
            ('maxcon', '50')
        ]
        rcv_options_values = [
            ('-msgsize', '1456'), 
            ('-reply', '0'), 
            ('-printmsg', '0')
        ]
        snd_attrs_values = [
            ('sndbuf', '12058624'), 
            ('smoother', 'live'), 
            ('maxbw', str(maxbw)),
        ]
        snd_options_values = [
            ('-msgsize', '1456'), 
            ('-reply', '0'), 
            ('-printmsg', '0',), 
            ('-bitrate', str(bitrate)),
            ('-repeat', str(repeat)),
        ]
        description = f'{global_config.scenario}-alg-{global_config.algdescr}-bitr-{bitrate / shared.DELIMETER}Mbps'
        
        exper_params = ExperimentParams(
            rcv_attrs_values,
            rcv_options_values,
            snd_attrs_values,
            snd_options_values,
            description,
            test_config.time_to_stream
        )

        yield exper_params


def get_query(attrs_values):
    query_elements = []
    for attr, value in attrs_values:
        query_elements.append(f'{attr}={value}')
    return f'{"&".join(query_elements)}'


def start_sender(
    number,
    path_to_srt: str,
    host: str,
    port: str,
    attrs_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    options_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    description: str=None,
    collect_stats: bool=False,
    results_dir: pathlib.Path=None
):
    name = f'srt sender {number}'
    logger.info(f'Starting on a local machine: {name}')

    args = []
    args += [f'{path_to_srt}/srt-test-messaging']

    if attrs_values is not None:
        # FIXME: But here there is a problem with "" because sender has been
        # started locally, not via SSH
        args += [f'srt://{host}:{port}?{get_query(attrs_values)}']
    else:
        args += [f'srt://{host}:{port}']

    args += ['']

    if options_values is not None:
        for option, value in options_values:
            args += [option, value]

    if collect_stats:
        stats_file = results_dir / f'{description}-stats-snd-{number}.csv'
        args += [
            '-statsfreq', '1',
            '-statsfile', stats_file,
        ]
    
    snd_srt_process = shared.create_process(name, args)
    logger.info(f'Started successfully: {name}')
    return (name, snd_srt_process)


def start_receiver(
    ssh_host: str, 
    ssh_username: str, 
    path_to_srt: str,
    host: str,
    port: str,
    attrs_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    options_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    description: str=None,
    collect_stats: bool=False,
    results_dir: pathlib.Path=None
):
    """
    Starts srt-test-messaging application on a receiver side via SSH.

    Attributes:
        attrs_values:
            A list of SRT options (SRT URI attributes) in a format
            [('rcvbuf', '12058624'), ('smoother', 'live'), ('maxcon', '50')].
        options_values:
            A list of srt-test-messaging application options in a format
            [('-msgsize', '1456'), ('-reply', '0'), ('-printmsg', '0')].
    """
    name = 'srt receiver'
    logger.info(f'Starting {name} on a remote machine: {ssh_host}')
    args = []
    args += shared.SSH_COMMON_ARGS
    args += [
        f'{ssh_username}@{ssh_host}',
        f'{path_to_srt}/srt-test-messaging',
    ]

    if attrs_values is not None:
        # FIXME: There is a problem with "" here, if to run an app via SSH,
        # it does not work without ""
        args += [f'"srt://{host}:{port}?{get_query(attrs_values)}"']
    else:
        args += [f'srt://{host}:{port}']

    if options_values is not None:
        for option, value in options_values:
            args += [option, value]

    if collect_stats:
        args += ['-statsfreq', '1']
        stats_file = results_dir / f'{description}-stats-rcv.csv'
        args += ['-statsfile', stats_file]
    
    process = shared.create_process(name, args, True)
    logger.info('Started successfully')
    return (name, process)


def start_several_senders(
    quantity: int,
    mode: str,
    path_to_srt: str,
    host: str,
    port: str,
    attrs_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    options_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    description: str=None,
    collect_stats: bool=False,
    results_dir: pathlib.Path=None
):
    
    # FIXME: Transfer bitrate and repeat
    # logger.info(
    #     f'Starting streaming with bitrate {bitrate}, repeat {repeat}, '
    #     f'senders {snd_number}'
    # )
    logger.info(
        f'Starting streaming: {description}, '
        f'senders {quantity}'
    )

    sender_processes = []

    if quantity == 1 or mode == 'serial':
        for i in range(0, quantity):
            snd_srt_process = start_sender(
                i,
                path_to_srt,
                host,
                port,
                attrs_values,
                options_values,
                description,
                collect_stats,
                results_dir
            )
            sender_processes.append(snd_srt_process)

    if mode == 'parallel':
        with concurrent.futures.ThreadPoolExecutor(max_workers=quantity) as executor:
            # TODO: Change to list (?)
            future_senders = {
                executor.submit(
                    start_sender, 
                    i,
                    path_to_srt,
                    host,
                    port,
                    attrs_values,
                    options_values,
                    description,
                    collect_stats,
                    results_dir
                ): i for i in range(0, quantity)
            }

            errors = 0
            for future in concurrent.futures.as_completed(future_senders):
                try:
                    process = future.result()
                except Exception as exc:
                    logger.info(
                        f'{future_senders[future]} sender generated an '
                        f'exception: {exc}'
                    )
                    errors += 1
                else:
                    sender_processes.append(process)

            if errors > 0:
                raise shared.ParallelSendersExecutionFailed()

    return sender_processes


def perform_experiment(
    global_config,
    exper_params: ExperimentParams,
    rcv: str,
    snd_quantity: int,
    snd_mode: str,
    collect_stats: bool=False,
    run_tshark: bool=False,
    results_dir: pathlib.Path=None
):
    """
    Performs one experiment.

    Returns:
        Extra time in seconds spent on SRT streaming.

    Raises:
        KeyboardInterrupt,
        shared.ProcessHasNotBeenStartedSuccessfully, 
        shared.ProcessHasNotBeenCreated,
        shared.ProcessHasNotBeenKilled
    """
    processes = []
    try:
        # Start SRT on a receiver side
        if rcv == 'remotely':
            rcv_srt_process = start_receiver(
                global_config.rcv_ssh_host, 
                global_config.rcv_ssh_username, 
                global_config.rcv_path_to_srt, 
                '',
                global_config.dst_port,
                exper_params.rcv_attrs_values,
                exper_params.rcv_options_values,
                exper_params.description,
                collect_stats,
                results_dir
            )
            processes.append(rcv_srt_process)
            time.sleep(3)

        # Start tshark on a sender side
        if run_tshark:
            filename = f'{exper_params.description}-snd.pcapng'
            snd_tshark_process = shared.start_tshark(
                global_config.snd_tshark_iface, 
                global_config.dst_port,
                results_dir,
                filename
            )
            processes.append(snd_tshark_process)
            time.sleep(3)

        # Start several SRT senders on a sender side to stream for
        # config.time_to_stream seconds
        sender_processes = start_several_senders(
            snd_quantity,
            snd_mode,
            global_config.snd_path_to_srt,
            global_config.dst_host,
            global_config.dst_port,
            exper_params.snd_attrs_values,
            exper_params.snd_options_values,
            exper_params.description,
            collect_stats,
            results_dir
        )
        for p in sender_processes:
            processes.append(p)

        # Sleep for config.time_to_stream seconds to wait while senders 
        # will finish the streaming and then check how many senders are 
        # still running.
        # FIXME: Time adjustment is needed for snd_mode='serial'
        time.sleep(exper_params.time_to_stream)
        extra_time = shared.calculate_extra_time(sender_processes)
        

        logger.info('Done')
        # time.sleep(3)
        return extra_time

        # if run_tshark:
        #     shared.cleanup_process(snd_tshark_process)
        #     time.sleep(3)
        # if rcv == 'remotely':
        #     shared.cleanup_process(rcv_srt_process)
        #     time.sleep(3)
    except KeyboardInterrupt:
        logger.info('KeyboardInterrupt has been caught')
        raise
    except (
        shared.ProcessHasNotBeenStartedSuccessfully, 
        shared.ProcessHasNotBeenCreated
    ) as error:
        logger.info(
            f'Exception occured ({error.__class__.__name__}): {error}'
        )
        raise
    finally:
        logger.info('Cleaning up')
        for process_tuple in reversed(processes):
            try:
                shared.cleanup_process(process_tuple)
            except shared.ProcessHasNotBeenKilled as error:
                # TODO: Collect the information regarding non killed processes
                # and perfom additional clean-up actions
                logger.info(
                    f'During cleaning up an exception occured '
                    f'({error.__class__.__name__}): {error}. The next '
                    f'experiment can not be done further!'
                )
                raise
        logger.info('Done')


def main_function(
    config_filepath: pathlib.Path,
    rcv: str,
    snd_quantity: int,
    snd_mode: str,
    collect_stats: bool=False,
    run_tshark: bool=False,
    results_dir: typing.Optional[pathlib.Path]=None
):
    global_config = GlobalConfig.from_config_filepath(config_filepath)
    test_config = BandwidthLoopTestConfig.from_config_filepath(config_filepath)

    try:
        if rcv == 'remotely':
            logger.info('Creating a folder for storing results on a receiver side')
            # FIXME: By default Paramiko will attempt to connect to a running 
            # SSH agent (Unix style, e.g. a live SSH_AUTH_SOCK, or Pageant if 
            # one is on Windows). That's why promt for login-password is not 
            # disabled under condition that password is not configured via 
            # connect_kwargs.password
            with fabric.Connection(host=global_config.rcv_ssh_host, user=global_config.rcv_ssh_username) as c:
                result = c.run(f'rm -rf {results_dir}')
                if result.exited != 0:
                    logger.info(f'Not created: {result}')
                    return
                result = c.run(f'mkdir {results_dir}')
                if result.exited != 0:
                    logger.info(f'Not created: {result}')
                    return
            logger.info('Created successfully')

        logger.info('Creating a folder for saving results on a sender side')
        results_dir = pathlib.Path(results_dir)
        if results_dir.exists():
            shutil.rmtree(results_dir)
        results_dir.mkdir()
        logger.info('Created successfully')
    except paramiko.ssh_exception.SSHException as error:
        logger.info(
            f'Exception occured ({error.__class__.__name__}): {error}'
        )
        return

    exper_params_generator = bw_loop_test_generator(global_config, test_config)

    # for bitrate in range(config.bitrate_min, config.bitrate_max, config.bitrate_step):
    for exper_params in exper_params_generator:
        try:
            extra_time = perform_experiment(
                global_config,
                exper_params,
                rcv,
                snd_quantity,
                snd_mode,
                collect_stats,
                run_tshark,
                results_dir
            )
            logger.info(f'Extra time spent on streaming: {extra_time}')
        except (KeyboardInterrupt, shared.ProcessHasNotBeenKilled):
            break
        except (
            shared.ProcessHasNotBeenStartedSuccessfully, 
            shared.ProcessHasNotBeenCreated
        ) as error:
            continue

        # (?) Criteria of not going further should be defined in generator,
        # (?) what would be in case of filecc
        if extra_time >= 5:
            # FIXME: Add bitrate support
            logger.info(
                f'Waited {exper_params.time_to_stream + extra_time} seconds '
                f'instead of {exper_params.time_to_stream}. '
                # f'{bitrate}bps is considered as maximim available bandwidth.'
            )
            break


@click.command()
@click.argument(
    'config_filepath', 
    type=click.Path(exists=True)
)
@click.option(
    '--rcv', 
    type=click.Choice(['manually', 'remotely']), 
    default='remotely',
    help=	'Start a receiver manually or remotely via SSH. In case of '
            'manual receiver start, please do not forget to do it '
            'before running the script.',
    show_default=True
)
@click.option(
    '--snd-quantity', 
    default=1,
    help=   'Number of senders to start.',
    show_default=True
)
@click.option(
    '--snd-mode',
    type=click.Choice(['serial', 'parallel']), 
    default='serial',
    help=   'Start senders concurrently or in parallel.',
    show_default=True
)
@click.option(
    '--collect-stats', 
    is_flag=True, 
    help='Collect SRT statistics.'
)
@click.option(
    '--run-tshark',
    is_flag=True,
    help='Run tshark.'
)
@click.option(
    '--results-dir',
    default='_results',
    help=   'Directory to store results.',
    show_default=True
)
def main(
    config_filepath,
    rcv,
    snd_quantity,
    snd_mode,
    collect_stats,
    run_tshark,
    results_dir
):
    main_function(
        pathlib.Path(config_filepath),
        rcv,
        snd_quantity,
        snd_mode,
        collect_stats,
        run_tshark,
        results_dir
    )


if __name__ == '__main__':
    main()