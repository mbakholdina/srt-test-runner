""" 
Bandwidth loop test.

A script that runs 1 receiver and N senders (concurrently, in parallel) 
which stream with a specified bitrate. This is done iteratively every time
with a different value of bitrate what helps to determine a maximum 
availabale bandwidth at the moment of running the script.
"""
import concurrent.futures
import configparser
import logging
import pathlib
import signal
import shutil
import subprocess
import sys
import time
import typing

import attr
import click
import fabric
import paramiko

import shared


# TODO:     Add an option to download stats and Wireshark dumps via scp (fabric),
#           Adjust time and the process of running N senders concurrently,
#           Test the script on Windows with regard to ssh-agent,
#           Disbale password promt (fabric),
#           Fix the problem with carriage (\r\n) generated by pseudo-terminal,
#           Add running tshark remotely on a receiver side,
#           Add running sender side application remotely (?),
#           Improve documentation,
#           Disable warnings from paramiko


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)-15s [%(levelname)s] %(message)s',
)
logger = logging.getLogger(__name__)


def get_query(attrs_values):
    query_elements = []
    for attr, value in attrs_values:
        query_elements.append(f'{attr}={value}')
    return f'{"&".join(query_elements)}'


def start_sender(
    path_to_srt: str,
    host: str,
    port: str,
    attrs_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    options_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    collect_stats: bool=False,
    results_dir: pathlib.Path=None,
    file_info=None,
    sender_number=None
):
    name = f'srt sender {sender_number}'
    logger.info(f'Starting on a local machine: {name}')

    args = []
    args += [f'{path_to_srt}/srt-test-messaging']

    if attrs_values is not None:
        # FIXME: But here there is a problem with "" because sender has been
        # started locally, not via SSH
        args += [f'srt://{host}:{port}?{get_query(attrs_values)}']
    else:
        args += [f'srt://{host}:{port}']

    args += ['']

    if options_values is not None:
        for option, value in options_values:
            args += [option, value]

    if collect_stats:
        scenario, algdescr, bitrate = file_info
        stats_file = results_dir / f'{scenario}-alg-{algdescr}-blt-{bitrate / shared.DELIMETER}Mbps-stats-snd-{sender_number}.csv'
        args += [
            '-statsfreq', '1',
            '-statsfile', stats_file,
        ]
    
    snd_srt_process = shared.create_process(name, args)
    logger.info(f'Started successfully: {name}')
    return (name, snd_srt_process)

def start_receiver(
    ssh_host: str, 
    ssh_username: str, 
    path_to_srt: str,
    host: str,
    port: str,
    attrs_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    options_values: typing.Optional[typing.List[typing.Tuple[str, str]]]=None,
    collect_stats: bool=False,
    results_dir: pathlib.Path=None,
    file_info=None
):
    """
    Starts srt-test-messaging application on a receiver side via SSH.

    Attributes:
        attrs_values:
            A list of SRT options (SRT URI attributes) in a format
            [('rcvbuf', '12058624'), ('smoother', 'live'), ('maxcon', '50')].
        options_values:
            A list of srt-test-messaging application options in a format
            [('-msgsize', '1456'), ('-reply', '0'), ('-printmsg', '0')].
    """
    name = 'srt receiver'
    logger.info(f'Starting {name} on a remote machine: {ssh_host}')
    args = []
    args += shared.SSH_COMMON_ARGS
    args += [
        f'{ssh_username}@{ssh_host}',
        f'{path_to_srt}/srt-test-messaging',
    ]

    if attrs_values is not None:
        # FIXME: There is a problem with "" here, if to run an app via SSH,
        # it does not work without ""
        args += [f'"srt://{host}:{port}?{get_query(attrs_values)}"']
    else:
        args += [f'srt://{host}:{port}']

    if options_values is not None:
        for option, value in options_values:
            args += [option, value]

    if collect_stats:
        args += ['-statsfreq', '1']
        scenario, algdescr, bitrate = file_info
        stats_file = results_dir / f'{scenario}-alg-{algdescr}-blt-{bitrate / shared.DELIMETER}Mbps-stats-rcv.csv'
        args += ['-statsfile', stats_file]
    
    process = shared.create_process(name, args, True)
    logger.info('Started successfully')
    return (name, process)

@attr.s
class Config:
    """
    Global configuration settings.
    """
    rcv_ssh_host: str = attr.ib()
    rcv_ssh_username: str = attr.ib()
    rcv_path_to_srt: str = attr.ib()
    snd_path_to_srt: str = attr.ib()
    snd_tshark_iface: str = attr.ib()
    dst_host: str = attr.ib()
    dst_port: str = attr.ib()
    algdescr: str = attr.ib()
    scenario: str = attr.ib()
    bitrate_min: int = attr.ib()
    bitrate_max: int = attr.ib()
    bitrate_step: int = attr.ib()
    time_to_stream: int = attr.ib()

    @classmethod
    def from_config_filepath(cls, config_filepath: pathlib.Path):
        parsed_config = configparser.ConfigParser()
        with config_filepath.open('r', encoding='utf-8') as fp:
            parsed_config.read_file(fp)
        return cls(
            parsed_config['receiver']['rcv_ssh_host'],
            parsed_config['receiver']['rcv_ssh_username'],
            parsed_config['receiver']['rcv_path_to_srt'],
            parsed_config['sender']['snd_path_to_srt'],
            parsed_config['sender']['snd_tshark_iface'],
            parsed_config['bw-loop-test']['dst_host'],
            parsed_config['bw-loop-test']['dst_port'],
            parsed_config['bw-loop-test']['algdescr'],
            parsed_config['bw-loop-test']['scenario'],
            int(parsed_config['bw-loop-test']['bitrate_min']),
            int(parsed_config['bw-loop-test']['bitrate_max']),
            int(parsed_config['bw-loop-test']['bitrate_step']),
            int(parsed_config['bw-loop-test']['time_to_stream'])
        )

def start_several_senders(
    config,
    bitrate,
    snd_number,
    snd_mode,
    results_dir,
    collect_stats,
    file_info
):
    # Calculate number of packets for time_to_stream sec of streaming
    # based on the target bitrate and packet size
    repeat = config.time_to_stream * bitrate // (1456 * 8)
    maxbw  = int(bitrate // 8 * 1.25)
    # params = (bitrate, repeat, maxbw)

    attrs_values = [
        ('sndbuf', '12058624'), 
        ('smoother', 'live'), 
        ('maxbw', str(maxbw)),
    ]
    options_values = [
        ('-msgsize', '1456'), 
        ('-reply', '0'), 
        ('-printmsg', '0',), 
        ('-bitrate', str(bitrate)),
        ('-repeat', str(repeat)),
    ]

    logger.info(
        f'Starting streaming with bitrate {bitrate}, repeat {repeat}, '
        f'senders {snd_number}'
    )

    sender_processes = []

    if snd_number == 1 or snd_mode == 'serial':
        for i in range(0, snd_number):
            snd_srt_process = start_sender(
                config.snd_path_to_srt,
                config.dst_host,
                config.dst_port,
                attrs_values,
                options_values,
                collect_stats,
                results_dir,
                file_info,
                i
            )
            sender_processes.append(snd_srt_process)

    if snd_mode == 'parallel':
        with concurrent.futures.ThreadPoolExecutor(max_workers=snd_number) as executor:
            # TODO: Change to list (?)
            future_senders = {
                executor.submit(
                    start_sender, 
                    config.snd_path_to_srt,
                    config.dst_host,
                    config.dst_port,
                    attrs_values,
                    options_values,
                    collect_stats,
                    results_dir,
                    file_info,
                    i
                ): i for i in range(0, snd_number)
            }

            errors = 0
            for future in concurrent.futures.as_completed(future_senders):
                try:
                    process = future.result()
                except Exception as exc:
                    logger.info(
                        f'{future_senders[future]} sender generated an '
                        f'exception: {exc}'
                    )
                    errors += 1
                else:
                    sender_processes.append(process)

            if errors > 0:
                raise shared.ParallelSendersExecutionFailed()

    return sender_processes

def perform_experiment(
    config,
    rcv,
    snd_number,
    snd_mode,
    results_dir,
    collect_stats,
    run_tshark,
    bitrate
):
    """
    Performs one experiment.

    Raises:
        KeyboardInterrupt,
        shared.ProcessHasNotBeenStartedSuccessfully, 
        shared.ProcessHasNotBeenCreated,
        shared.ProcessHasNotBeenKilled
    """
    processes = []
    try:
        # Information needed to form .csv stats and .pcapng WireShark
        # files' names
        file_info = (config.scenario, config.algdescr, bitrate)

        # Start SRT on a receiver side
        attrs_values = [('rcvbuf', '12058624'), ('smoother', 'live'), ('maxcon', '50')]
        options_values = [('-msgsize', '1456'), ('-reply', '0'), ('-printmsg', '0')]
        if rcv == 'remotely':
            rcv_srt_process = start_receiver(
                config.rcv_ssh_host, 
                config.rcv_ssh_username, 
                config.rcv_path_to_srt, 
                '',
                config.dst_port,
                attrs_values,
                options_values,
                collect_stats,
                results_dir,
                file_info
            )
            processes.append(rcv_srt_process)
            time.sleep(3)

        # Start tshark on a sender side
        if run_tshark:
            filename = f'{config.scenario}-alg-{config.algdescr}-blt-{bitrate / shared.DELIMETER}Mbps-snd.pcapng'
            snd_tshark_process = shared.start_tshark(
                config.snd_tshark_iface, 
                config.dst_port, 
                filename,
                results_dir
            )
            processes.append(snd_tshark_process)
            time.sleep(3)

        # Start several SRT senders on a sender side to stream for
        # config.time_to_stream seconds
        sender_processes = start_several_senders(
            config,
            bitrate,
            snd_number,
            snd_mode,
            results_dir,
            collect_stats,
            file_info
        )
        for p in sender_processes:
            processes.append(p)

        # Sleep for config.time_to_stream seconds to wait while senders 
        # will finish the streaming and then check how many senders are 
        # still running.
        # FIXME: Time adjustment is needed for snd_mode='serial'
        time.sleep(config.time_to_stream)
        extra_time = shared.calculate_extra_time(sender_processes)
        logger.info(f'Extra time spent on streaming: {extra_time}')

        logger.info('Done')
        # time.sleep(3)
        return extra_time

        # if run_tshark:
        #     shared.cleanup_process(snd_tshark_process)
        #     time.sleep(3)
        # if rcv == 'remotely':
        #     shared.cleanup_process(rcv_srt_process)
        #     time.sleep(3)
    except KeyboardInterrupt:
        logger.info('KeyboardInterrupt has been caught')
        raise
    except (
        shared.ProcessHasNotBeenStartedSuccessfully, 
        shared.ProcessHasNotBeenCreated
    ) as error:
        logger.info(
            f'Exception occured ({error.__class__.__name__}): {error}'
        )
        raise
    finally:
        logger.info('Cleaning up')
        for process_tuple in reversed(processes):
            try:
                shared.cleanup_process(process_tuple)
            except shared.ProcessHasNotBeenKilled as error:
                # TODO: Collect the information regarding non killed processes
                # and perfom additional clean-up actions
                logger.info(
                    f'During cleaning up an exception occured '
                    f'({error.__class__.__name__}): {error}. The next '
                    f'experiment can not be done further!'
                )
                raise
        logger.info('Done')


def main_function(
    config_filepath,
    rcv,
    snd_number,
    snd_mode,
    results_dir,
    collect_stats,
    run_tshark
):
    config = Config.from_config_filepath(pathlib.Path(config_filepath))

    try:
        if rcv == 'remotely':
            logger.info('Creating a folder for storing results on a receiver side')
            # FIXME: By default Paramiko will attempt to connect to a running 
            # SSH agent (Unix style, e.g. a live SSH_AUTH_SOCK, or Pageant if 
            # one is on Windows). That's why promt for login-password is not 
            # disabled under condition that password is not configured via 
            # connect_kwargs.password
            with fabric.Connection(host=config.rcv_ssh_host, user=config.rcv_ssh_username) as c:
                result = c.run(f'rm -rf {results_dir}')
                if result.exited != 0:
                    logger.info(f'Not created: {result}')
                    return
                result = c.run(f'mkdir {results_dir}')
                if result.exited != 0:
                    logger.info(f'Not created: {result}')
                    return
            logger.info('Created successfully')

        logger.info('Creating a folder for saving results on a sender side')
        results_dir = pathlib.Path(results_dir)
        if results_dir.exists():
            shutil.rmtree(results_dir)
        results_dir.mkdir()
        logger.info('Created successfully')
    except paramiko.ssh_exception.SSHException as error:
        logger.info(
            f'Exception occured ({error.__class__.__name__}): {error}'
        )
        return

    for bitrate in range(config.bitrate_min, config.bitrate_max, config.bitrate_step):
        try:
            # raise shared.ProcessHasNotBeenKilled()
            extra_time = perform_experiment(
                config,
                rcv,
                snd_number,
                snd_mode,
                results_dir,
                collect_stats,
                run_tshark,
                bitrate
            )

        except (KeyboardInterrupt, shared.ProcessHasNotBeenKilled):
            break
        except (
            shared.ProcessHasNotBeenStartedSuccessfully, 
            shared.ProcessHasNotBeenCreated
        ) as error:
            continue

        # (?) Criteria of not going further should be defined in generator,
        # (?) what would be in case of filecc
        if extra_time >= 5:
            logger.info(
                f'Waited {config.time_to_stream + extra_time} seconds '
                f'instead of {config.time_to_stream}. '
                f'{bitrate}bps is considered as maximim available bandwidth.'
            )
            break


@click.command()
@click.argument(
    'config_filepath', 
    type=click.Path(exists=True)
)
@click.option(
    '--rcv', 
    type=click.Choice(['manually', 'remotely']), 
    default='remotely',
    help=	'Start a receiver manually or remotely via SSH. In case of '
            'manual receiver start, please do not forget to do it '
            'before running the script.',
    show_default=True
)
@click.option(
    '--snd-number', 
    default=1,
    help=   'Number of senders to start.',
    show_default=True
)
@click.option(
    '--snd-mode',
    type=click.Choice(['serial', 'parallel']), 
    default='serial',
    help=   'Start senders concurrently or in parallel.',
    show_default=True
)
@click.option(
    '--results-dir',
    default='_results',
    help=   'Directory to store results.',
    show_default=True
)
@click.option(
    '--collect-stats', 
    is_flag=True, 
    help='Collect SRT statistics.'
)
@click.option(
    '--run-tshark',
    is_flag=True,
    help='Run tshark.'
)
def main(
    config_filepath,
    rcv,
    snd_number,
    snd_mode,
    results_dir,
    collect_stats,
    run_tshark
):
    main_function(
        config_filepath,
        rcv,
        snd_number,
        snd_mode,
        results_dir,
        collect_stats,
        run_tshark
    )


if __name__ == '__main__':
    main()